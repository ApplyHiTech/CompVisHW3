{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Homework 3 Task 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import scipy.cluster as cluster\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 3.1 -- LOAD IMAGES AND SHOW THEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# LOAD\n",
    "images =[]\n",
    "images.append(mpimg.imread('HW3/Images/Q3/15.bmp'))\n",
    "images.append(mpimg.imread('HW3/Images/Q3/171.bmp'))\n",
    "images.append(mpimg.imread('HW3/Images/Q3/45.bmp'))\n",
    "images.append(mpimg.imread('HW3/Images/Q3/81.bmp'))\n",
    "\n",
    "# SHOW\n",
    "f,ax = plt.subplots(2,2)\n",
    "ax[0][0].imshow(images[0],cmap=\"gray\")\n",
    "ax[0][0].set_title('Image 1 - Many Trees')\n",
    "ax[0][1].imshow(images[1],cmap=\"gray\")\n",
    "ax[0][1].set_title('Image 2 - Many Patterns')\n",
    "ax[1][0].imshow(images[2],cmap=\"gray\")\n",
    "ax[1][0].set_title('Image 3 - Two Trees and a boat')\n",
    "ax[1][1].imshow(images[3],cmap=\"gray\")\n",
    "ax[1][1].set_title('Image 4 - A large boat')\n",
    "\n",
    "plt.show()\n",
    "#for i in range(4):\n",
    "#    ax[i].imshow(images[i],cmap=\"gray\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image 1 inlcudes many similarly looking trees at the bottom of the image and many similar looking trees at the top of the image.\n",
    "The trees seem to have a similar pattern and texture. The water in between the trees also seems to have the texture. \n",
    "There seems to be a white \"coastline\" that can be identified as \"edges\" between the weater and the top trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image 2: This image seems to be a concatenation of many different rectangles and square patterns. The texture changes repeatly across the image in both teh horizontal and vertical directions in distinct areas as if several square patches with perfectly concatenated. there seem to be clear horizontal and vertical lines separating the groups, but it is not easy to detect individual edges by pixel colors. The eye identifies the area. \n",
    "\n",
    "Image 3: There are two similar looking trees on the left and right side of hte image. Their texture is the similar. There are clouds with simlar texture. A beach in the distance with similar texture. And, a boat with a distinct whilte sail. The water, is identifiable, because of the presence of the boat, however, the reflections of the clouds make it quite difficult to distinguish. \n",
    "\n",
    "The trees in the background of the picture are similar looking. Without seeing the close trees or the boat they are not easily identifiable. There may even be several people on the beach as there are small dark areas. These areas could also be shadows of trees. \n",
    "\n",
    "Image 4: there is a boat in the middle of the water. The texture of the water is \"wavey\", The pixel colors change in a similar pattern acrooss the ocean. There boat has a clear black edge distinguishing the start of the boat and end of the water. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = images[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
    "sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
    "\n",
    "plt.subplot(2,2,1),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(2,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_orientation(sobelx,sobely):\n",
    "    dim = sobelx.shape\n",
    "    sobel_orientation = np.zeros(dim)\n",
    "\n",
    "    for i in range(sobelx.shape[0]):\n",
    "        for j in range(sobelx.shape[1]):\n",
    "            m_y = sobely[i][j]\n",
    "            m_x = sobelx[i][j]\n",
    "            theta = math.atan2(m_y,m_x)\n",
    "            sobel_orientation[i][j]=theta\n",
    "    return sobel_orientation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_magnitude(sobelx,sobely):\n",
    "    dim = sobelx.shape\n",
    "    sobel_magnitude = np.zeros(dim)\n",
    "\n",
    "    for i in range(sobelx.shape[0]):\n",
    "        for j in range(sobelx.shape[1]):\n",
    "            m_y = sobely[i][j]\n",
    "            m_x = sobelx[i][j]\n",
    "            magnitude = math.sqrt(m_y*m_y + m_x*m_x)\n",
    "            \n",
    "            sobel_magnitude[i][j]=magnitude\n",
    "    return sobel_magnitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_orientation_magnitude(sobelx,sobely):\n",
    "    sobel_orientation = compute_orientation(sobelx,sobely)\n",
    "    sobel_magnitude = compute_magnitude(sobelx,sobely)\n",
    "    \n",
    "    plt.subplot(3,2,1),plt.imshow(img,cmap = 'gray')\n",
    "    plt.title('Original'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,2,3),plt.imshow(sobelx,cmap = 'gray')\n",
    "    plt.title('Sobel X'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,2,4),plt.imshow(sobely,cmap = 'gray')\n",
    "    plt.title('Sobel Y'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,2,5),plt.imshow(sobel_orientation,cmap = 'gray')\n",
    "    plt.title('Orientation'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,2,6),plt.imshow(sobel_magnitude,cmap = 'gray')\n",
    "    plt.title('Magnitude'), plt.xticks([]), plt.yticks([])\n",
    "    \n",
    "    \n",
    "    return sobel_orientation, sobel_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobel_orientation, sobel_magnitude = show_orientation_magnitude(sobelx,sobely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quantize_orientation_angle(angle,cutoff,val):\n",
    "    k = True\n",
    "    i = 0\n",
    "    while ( k == True and i < len(cutoff) ):\n",
    "        \n",
    "        if (angle <= cutoff[i]):\n",
    "            k = False\n",
    "            return val[i]\n",
    "        i = i+1 \n",
    "    return val[i]\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantize_orientation(sobel_orientation,bins):\n",
    "    #Create the cutoffs, and rounding values.  \n",
    "    cutoff = []\n",
    "    val = []\n",
    "    dim = sobel_orientation.shape\n",
    "    sobel_orientation_quantized = np.zeros(dim)\n",
    "\n",
    "    for i in range(1,bins*2):\n",
    "        if (i%2 == 0):\n",
    "            cutoff.append(np.percentile(sobel_orientation,6.125*i))\n",
    "        else:\n",
    "            val.append(np.percentile(sobel_orientation,6.125*i))\n",
    "    \n",
    "    for i in range(sobel_orientation.shape[0]):\n",
    "        for j in range(sobel_orientation.shape[1]):\n",
    "            sobel_orientation_quantized[i][j] = quantize_orientation_angle(sobel_orientation[i][j],cutoff,val)\n",
    "            \n",
    "        \n",
    "    return sobel_orientation_quantized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobel_orientation_quantized = quantize_orientation(sobel_orientation,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_sobel_quantized(img):\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=3)\n",
    "    sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=3)\n",
    "    sobel_orientation = compute_orientation(sobelx,sobely)\n",
    "    sobel_orientation_quantized = quantize_orientation(sobel_orientation,8)\n",
    "    plt.subplot(1,2,1),plt.imshow(sobel_orientation,cmap = 'gray')\n",
    "    plt.title('Sobel-Orientation'), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(1,2,2),plt.imshow(sobel_orientation_quantized,cmap = 'gray')\n",
    "    plt.title('Sobel-Orientation-Quantized'), plt.xticks([]), plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_sobel_quantized(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Descriptor\n",
    "#- Create a feature vector for every pixel, looking at it's 11x11 neighborhood\n",
    "#- For each feature vector, there are 8 dimensions, where each dimension has a weight corresponding to the count of orientations with a magnitude above threshold, T\n",
    "#- Boundaries are handled because \"outside\" pixels have a threshold below T (assuming zero padding)\n",
    "\n",
    "#Padding.\n",
    "\n",
    "#sobel_magnitude\n",
    "#sobel_orientation_quantized\n",
    "\n",
    "\n",
    "def compute_descriptor(sobel_magnitude,sobel_orientation_quantized,threshold):\n",
    "    dim = sobel_orientation_quantized.shape\n",
    "    #descriptor = np.zeros(dim) --- NP.array only accepts values.\n",
    "    descriptor = [[0 for x in range(dim[0])] for x in range(dim[1])] ### lists accept tuple values.\n",
    "    \n",
    "    for i in range(len(descriptor)):\n",
    "        for j in range(len(descriptor[0])):\n",
    "            descriptor[i][j] = compute_descriptor_for_pixel(sobel_orientation_quantized,i,j,threshold,sobel_magnitude)\n",
    "            #if sobel_magnitude[i][j]>threshold:\n",
    "             #   #Create a feature vector for every pixel, looking at its 11x11 neighborhood.\n",
    "            #    descriptor[i][j] = compute_descriptor_for_pixel(sobel_orientation_quantized,i,j)\n",
    "            #else:\n",
    "            #    descriptor[i][j] = np.zeros(8) \n",
    "    \n",
    "    descriptor_array = np.array(descriptor)\n",
    "    return descriptor_array.reshape(descriptor_array.shape[0]*descriptor_array.shape[1],descriptor_array.shape[2]),[descriptor_array.shape[0],\n",
    "                                                                                                                    descriptor_array.shape[1]]\n",
    "\n",
    "def compute_descriptor_for_pixel(sobel_orientation_quantized,i,j,threshold,sobel_magnitude):\n",
    "    #get submatrix.\n",
    "    #border bases. \n",
    "    x_low = i-5\n",
    "    y_low = j-5\n",
    "    x_high = i+6\n",
    "    y_high = j+6\n",
    "    \n",
    "    if i < 5:\n",
    "        x_low = 0\n",
    "        x_high = i+6\n",
    "\n",
    "    if j < 5:\n",
    "        y_low = 0\n",
    "        y_high = j+6\n",
    "       \n",
    "    if i>sobel_orientation_quantized.shape[0]-6:\n",
    "        x_low = i-6\n",
    "        x_high = sobel_orientation_quantized.shape[0]\n",
    "    if j>sobel_orientation_quantized.shape[1]-6:\n",
    "        y_low = j-6\n",
    "        y_high = sobel_orientation_quantized.shape[1]\n",
    "    submatrix = sobel_orientation_quantized[x_low:x_high,y_low:y_high]\n",
    "    subsobel = sobel_magnitude[x_low:x_high,y_low:y_high]\n",
    "    for i in range(subsobel.shape[0]):\n",
    "        for j in range(subsobel.shape[1]):\n",
    "            if (subsobel[i][j] < threshold):\n",
    "                submatrix[i][j] = 0 \n",
    "               \n",
    "    return np.histogram(np.reshape(submatrix,-1),8)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descriptor, descriptor_dimensioms = compute_descriptor(sobel_magnitude,sobel_orientation_quantized,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compute_centroids_labels(descriptor,5,descriptor_dimensioms)\n",
    "descriptor\n",
    "#numb_clusters=5\n",
    "#centroids,b =  cluster.vq.kmeans2(descriptor,numb_clusters)\n",
    "\n",
    "est = KMeans(n_clusters=5)\n",
    "est.fit(descriptor)\n",
    "labels = est.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.histogram(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute Centroids for 5, 10, 50 clusters. \n",
    "\n",
    "def compute_centroids_labels(descriptor,numb_clusters,descriptor_dimensioms): \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "    #centroids,labels =  cluster.vq.kmeans2(descriptor,numb_clusters)\n",
    "    est = KMeans(n_clusters=numb_clusters)\n",
    "    est.fit(descriptor)\n",
    "    labels = est.labels_\n",
    "\n",
    "    # Reshape the labels \n",
    "    \n",
    "    return labels.reshape(descriptor_dimensioms[0],descriptor_dimensioms[1])\n",
    "\n",
    "def show_centroids_colormap(image,numb_clusters,threshold,discrete_bins=8,colorlist=['white','yellow','green','blue','black','red']):\n",
    "   \n",
    "    sobelx = cv2.Sobel(image,cv2.CV_64F,1,0,ksize=3)\n",
    "    sobely = cv2.Sobel(image,cv2.CV_64F,0,1,ksize=3)\n",
    "    \n",
    "    sobel_orientation = compute_orientation(sobelx,sobely)\n",
    "    sobel_magnitude = compute_magnitude(sobelx,sobely)\n",
    "    \n",
    "    sobel_orientation_quantized = quantize_orientation(sobel_orientation,discrete_bins)\n",
    "    \n",
    "    descriptor,descriptor_dimensioms = compute_descriptor(sobel_magnitude,sobel_orientation_quantized,threshold)\n",
    "    \n",
    "    labels_square = compute_centroids_labels(descriptor,numb_clusters,descriptor_dimensioms)\n",
    "    # If label = number then different color.... \n",
    "    fig = pyplot.figure()\n",
    "    cmap2 = mpl.colors.LinearSegmentedColormap.from_list('my_colormap',colorlist,numb_clusters)\n",
    "    img2 = pyplot.imshow(labels_square,interpolation='nearest',cmap = cmap2,origin='lower')\n",
    "    pyplot.colorbar(img2,cmap=cmap2)\n",
    "    fig.savefig(\"image2.png\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_centroids_colormap(images[0],5,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the results and discuss them. What do you see? Does it make sense? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_centroids_colormap(images[3],5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_centroids_colormap(images[1],10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_centroids_colormap(images[0],10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
